# Awesome Mamba (S4 - Structured State Space Models)

![Awesome](https://awesome.re/badge.svg)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![GitHub Contributors](https://img.shields.io/github/contributors/gauravfs-14/awesome-mamba.svg)
![GitHub Last Commit](https://img.shields.io/github/last-commit/gauravfs-14/awesome-mamba.svg)
[![GitHub Stars](https://img.shields.io/github/stars/gauravfs-14/awesome-mamba.svg?style=social)](https://github.com/gauravfs-14/awesome-mamba)
![GitHub Forks](https://img.shields.io/github/forks/gauravfs-14/awesome-mamba.svg)

A carefully curated collection of high-quality libraries, projects, tutorials, research papers, and other essential resources focused on Structured State Space Models (SSMs), with a special emphasis on S4, Mamba, and their variants. This repository is designed to be a comprehensive, well-organized knowledge base for researchers and developers delving into the rapidly evolving landscape of sequence modeling using SSMs.

To ensure that the community stays informed of cutting-edge developments, our repository is automatically updated with the latest S4/Mamba-related research papers from arXiv. This feature guarantees that you have access to the most recent advancements in the field, making it an invaluable resource for anyone interested in SSMs.

Whether you're a researcher exploring long-range dependencies, a developer building efficient sequence models, or simply an enthusiast in machine learning, this collection serves as a centralized hub for everything related to S4, Mamba, and the broader family of state space models, enriched by original peer-reviewed contributions to the field.

## Last Updated
July 29, 2025 at 02:01:32 AM UTC


## Theorem

## Papers (44)
- [From S4 to Mamba: A Comprehensive Survey on Structured State Space Models](https://arxiv.org/abs/2503.18970)
- [W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling](https://arxiv.org/abs/2506.07920)
- [Technologies on Effectiveness and Efficiency: A Survey of State Spaces Models](https://arxiv.org/abs/2503.11224)
- [MinGRU-Based Encoder for Turbo Autoencoder Frameworks](https://arxiv.org/abs/2503.08451)
- [S4M: S4 for multivariate time series forecasting with Missing values](https://arxiv.org/abs/2503.00900)
- [FusionMamba: Dynamic Feature Enhancement for Multimodal Image Fusion with Mamba](https://arxiv.org/abs/2404.09498)
- [Theoretical Foundations of Deep Selective State-Space Models](https://arxiv.org/abs/2402.19047)
- [SSM2Mel: State Space Model to Reconstruct Mel Spectrogram from the EEG](https://arxiv.org/abs/2501.10402)
- [IMSSA: Deploying modern state-space models on memristive in-memory compute hardware](https://arxiv.org/abs/2412.20215)
- [Latent Diffusion for Neural Spiking Data](https://arxiv.org/abs/2407.08751)
- [Slot State Space Models](https://arxiv.org/abs/2406.12272)
- [Provable Benefits of Complex Parameterizations for Structured State Space Models](https://arxiv.org/abs/2410.14067)
- [PRF: Parallel Resonate and Fire Neuron for Long Sequence Learning in Spiking Neural Networks](https://arxiv.org/abs/2410.03530)
- [Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning](https://arxiv.org/abs/2402.15761)
- [Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211)
- [Long Range Switching Time Series Prediction via State Space Model](https://arxiv.org/abs/2407.19201)
- [Model Compression Method for S4 with Diagonal State Space Layers using Balanced Truncation](https://arxiv.org/abs/2402.15993)
- [Dual Hyperspectral Mamba for Efficient Spectral Compressive Imaging](https://arxiv.org/abs/2406.00449)
- [Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors](https://arxiv.org/abs/2310.02980)
- [Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges](https://arxiv.org/abs/2404.16112)
- [Spiking Structured State Space Model for Monaural Speech Enhancement](https://arxiv.org/abs/2309.03641)
- [Incorporating Exponential Smoothing into MLP: A Simple but Effective Sequence Model](https://arxiv.org/abs/2403.17445)
- [Modeling Analog Dynamic Range Compressors using Deep Learning and State-space Models](https://arxiv.org/abs/2403.16331)
- [Assessing the importance of long-range correlations for deep-learning-based sleep staging](https://arxiv.org/abs/2402.17779)
- [Augmenting conformers with structured state-space sequence models for online speech recognition](https://arxiv.org/abs/2309.08551)
- [Structured State Space Models for In-Context Reinforcement Learning](https://arxiv.org/abs/2303.03982)
- [Facing Off World Model Backbones: RNNs, Transformers, and S4](https://arxiv.org/abs/2307.02064)
- [Robustifying State-space Models for Long Sequences via Approximate Diagonalization](https://arxiv.org/abs/2310.01698)
- [MNISQ: A Large-Scale Quantum Circuit Dataset for Machine Learning on/for Quantum Computers in the NISQ era](https://arxiv.org/abs/2306.16627)
- [Efficient Movie Scene Detection using State-Space Transformers](https://arxiv.org/abs/2212.14427)
- [A Multi-dimensional Deep Structured State Space Approach to Speech Enhancement Using Small-footprint Models](https://arxiv.org/abs/2306.00331)
- [State Spaces Aren't Enough: Machine Translation Needs Attention](https://arxiv.org/abs/2304.12776)
- [Selective Structured State-Spaces for Long-Form Video Understanding](https://arxiv.org/abs/2303.14526)
- [Transcription free filler word detection with Neural semi-CRFs](https://arxiv.org/abs/2303.06475)
- [Simplified State Space Layers for Sequence Modeling](https://arxiv.org/abs/2208.04933)
- [Long Movie Clip Classification with State-Space Video Models](https://arxiv.org/abs/2204.01692)
- [Structured State Space Decoder for Speech Recognition and Synthesis](https://arxiv.org/abs/2210.17098)
- [What Makes Convolutional Models Great on Long Sequence Modeling?](https://arxiv.org/abs/2210.09298)
- [Liquid Structural State-Space Models](https://arxiv.org/abs/2209.12951)
- [Efficiently Modeling Long Sequences with Structured State Spaces](https://arxiv.org/abs/2111.00396)
- [How to Train Your HiPPO: State Space Models with Generalized Orthogonal Basis Projections](https://arxiv.org/abs/2206.12037)
- [Improving the Diagnosis of Psychiatric Disorders with Self-Supervised Graph State Space Models](https://arxiv.org/abs/2206.03331)
- [Diagonal State Spaces are as Effective as Structured State Spaces](https://arxiv.org/abs/2203.14343)
- [Photo-z outlier self-calibration in weak lensing surveys](https://arxiv.org/abs/2007.12795)


## Library

## Tutorial

### Written Tutorials

### Video Tutorials

## Contributing

We welcome contributions to this repository! If you have a resource that you believe should be included, please submit a pull request or open an issue. Contributions can include:

- New libraries or tools related to S4/Mamba
- Tutorials or guides that help users understand and implement SSMs
- Research papers that advance the field of SSMs
- Any other resources that you find valuable for the community

## How to Contribute

1. Fork the repository.
2. Create a new branch for your changes.
3. Make your changes and commit them with a clear message.
4. Push your changes to your forked repository.
5. Submit a pull request to the main repository.

Before contributing, take a look at the existing resources to avoid duplicates.

## License

This repository is licensed under the [Creative Commons Attribution 4.0 International License (CC BY 4.0)](LICENSE). You are free to share and adapt the material, provided you give appropriate credit, link to the license, and indicate if changes were made.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gauravfs-14/awesome-mamba)](https://star-history.com/#gauravfs-14/awesome-mamba&Date)
